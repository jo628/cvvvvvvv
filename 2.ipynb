{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2edb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Recycled Materials Classification Project\n",
    "\n",
    "A complete pipeline for preprocessing, segmentation, feature extraction, \n",
    "classification, evaluation, and GUI for recycled materials detection.\n",
    "\n",
    "Classes:\n",
    "- Boxes (0)\n",
    "- Metal (1)\n",
    "- Plastic (2)\n",
    "\n",
    "Author: Zeyad-Diaa-1242\n",
    "Date: 2025-05-08\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "\n",
    "# Global variables\n",
    "IMAGE_SIZE = (128, 128)  # Reduced size for memory efficiency\n",
    "NUM_CLASSES = 3\n",
    "CLASS_NAMES = ['Boxes', 'Metal', 'Plastic']\n",
    "\n",
    "#############################################################\n",
    "# CELL 1: DATA LOADING AND VISUALIZATION\n",
    "#############################################################\n",
    "\n",
    "def load_dataset(dataset_dir=\"./dataset\"):\n",
    "    \"\"\"\n",
    "    Load images and labels from the dataset directory\n",
    "    \"\"\"\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    \n",
    "    # Load training data\n",
    "    try:\n",
    "        with open(os.path.join(dataset_dir, \"labels\", \"train.txt\"), \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 2:\n",
    "                    img_path = parts[0]\n",
    "                    # Handle relative paths\n",
    "                    if img_path.startswith(\"./dataset\"):\n",
    "                        img_path = img_path.replace(\"./dataset\", dataset_dir)\n",
    "                    label = int(parts[1])\n",
    "                    \n",
    "                    # Check if file exists\n",
    "                    if os.path.exists(img_path):\n",
    "                        train_data.append(img_path)\n",
    "                        train_labels.append(label)\n",
    "                    else:\n",
    "                        print(f\"Warning: File {img_path} not found\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading training data: {e}\")\n",
    "        return ([], []), ([], [])\n",
    "    \n",
    "    # Load test data\n",
    "    test_data = []\n",
    "    test_labels = []\n",
    "    try:\n",
    "        with open(os.path.join(dataset_dir, \"labels\", \"test.txt\"), \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 2:\n",
    "                    img_path = parts[0]\n",
    "                    # Handle relative paths\n",
    "                    if img_path.startswith(\"./dataset\"):\n",
    "                        img_path = img_path.replace(\"./dataset\", dataset_dir)\n",
    "                    label = int(parts[1])\n",
    "                    \n",
    "                    # Check if file exists\n",
    "                    if os.path.exists(img_path):\n",
    "                        test_data.append(img_path)\n",
    "                        test_labels.append(label)\n",
    "                    else:\n",
    "                        print(f\"Warning: File {img_path} not found\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading test data: {e}\")\n",
    "        if not train_data:\n",
    "            return ([], []), ([], [])\n",
    "    \n",
    "    print(f\"Loaded {len(train_data)} training images and {len(test_data)} test images\")\n",
    "    return (train_data, train_labels), (test_data, test_labels)\n",
    "\n",
    "def visualize_dataset_samples(data, labels, num_samples=2):\n",
    "    \"\"\"\n",
    "    Visualize random samples from the dataset\n",
    "    \"\"\"\n",
    "    if not data or not labels:\n",
    "        print(\"No data to visualize\")\n",
    "        return\n",
    "        \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(num_samples):\n",
    "        for class_id in range(NUM_CLASSES):\n",
    "            # Find samples of this class\n",
    "            indices = [idx for idx, label in enumerate(labels) if label == class_id]\n",
    "            if indices:\n",
    "                sample_idx = random.choice(indices)\n",
    "                img_path = data[sample_idx]\n",
    "                try:\n",
    "                    img = cv2.imread(img_path)\n",
    "                    if img is None:\n",
    "                        print(f\"Warning: Could not read image at {img_path}\")\n",
    "                        continue\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    \n",
    "                    plt.subplot(num_samples, NUM_CLASSES, i*NUM_CLASSES + class_id + 1)\n",
    "                    plt.imshow(img)\n",
    "                    plt.title(f\"{CLASS_NAMES[class_id]}\")\n",
    "                    plt.axis('off')\n",
    "                except Exception as e:\n",
    "                    print(f\"Error visualizing {img_path}: {e}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#############################################################\n",
    "# CELL 2: PREPROCESSING AND IMAGE ENHANCEMENT\n",
    "#############################################################\n",
    "\n",
    "def preprocess_image(image_path, target_size=IMAGE_SIZE):\n",
    "    \"\"\"\n",
    "    Preprocess an image: resize, normalize, and enhance\n",
    "    \"\"\"\n",
    "    # Read image\n",
    "    try:\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Could not read image at {image_path}\")\n",
    "        \n",
    "        # Convert from BGR to RGB\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Resize image\n",
    "        img_resized = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        # Apply noise reduction\n",
    "        img_denoised = cv2.fastNlMeansDenoisingColored(img_resized, None, 10, 10, 7, 21)\n",
    "        \n",
    "        # Enhance contrast using CLAHE\n",
    "        lab = cv2.cvtColor(img_denoised, cv2.COLOR_RGB2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        l = clahe.apply(l)\n",
    "        lab = cv2.merge((l, a, b))\n",
    "        img_enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
    "        \n",
    "        # Normalize pixel values to [0, 1]\n",
    "        img_normalized = img_enhanced.astype(np.float32) / 255.0\n",
    "        \n",
    "        return img_normalized, img\n",
    "    except Exception as e:\n",
    "        print(f\"Error preprocessing image {image_path}: {e}\")\n",
    "        # Return a blank image of the correct size and type\n",
    "        blank = np.zeros((*target_size, 3), dtype=np.float32)\n",
    "        return blank, blank\n",
    "\n",
    "def apply_augmentation(image):\n",
    "    \"\"\"\n",
    "    Apply random augmentations to increase dataset diversity\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Random horizontal flip\n",
    "        if random.random() > 0.5:\n",
    "            image = cv2.flip(image, 1)\n",
    "        \n",
    "        # Random rotation\n",
    "        angle = random.uniform(-15, 15)\n",
    "        h, w = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1)\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "        \n",
    "        # Random brightness and contrast adjustment\n",
    "        alpha = random.uniform(0.8, 1.2)  # Contrast\n",
    "        beta = random.uniform(-10, 10)    # Brightness\n",
    "        image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "        \n",
    "        # Random blur\n",
    "        if random.random() > 0.7:\n",
    "            image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "        \n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(f\"Error in augmentation: {e}\")\n",
    "        return image\n",
    "\n",
    "def visualize_preprocessing(image_path):\n",
    "    \"\"\"\n",
    "    Visualize the preprocessing steps on an example image\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Original image\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not read image at {image_path}\")\n",
    "            return\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Resized image\n",
    "        img_resized = cv2.resize(img, IMAGE_SIZE)\n",
    "        \n",
    "        # Denoised image\n",
    "        img_denoised = cv2.fastNlMeansDenoisingColored(img_resized, None, 10, 10, 7, 21)\n",
    "        \n",
    "        # Enhanced contrast\n",
    "        lab = cv2.cvtColor(img_denoised, cv2.COLOR_RGB2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        l = clahe.apply(l)\n",
    "        lab = cv2.merge((l, a, b))\n",
    "        img_enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
    "        \n",
    "        # Normalized\n",
    "        img_normalized = img_enhanced.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Augmented\n",
    "        img_augmented = apply_augmentation(img_enhanced)\n",
    "        \n",
    "        # Visualize\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        plt.subplot(2, 3, 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title('Original')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(2, 3, 2)\n",
    "        plt.imshow(img_resized)\n",
    "        plt.title('Resized')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(2, 3, 3)\n",
    "        plt.imshow(img_denoised)\n",
    "        plt.title('Denoised')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(2, 3, 4)\n",
    "        plt.imshow(img_enhanced)\n",
    "        plt.title('Enhanced Contrast')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(2, 3, 5)\n",
    "        plt.imshow(img_normalized)\n",
    "        plt.title('Normalized')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(2, 3, 6)\n",
    "        plt.imshow(img_augmented)\n",
    "        plt.title('Augmented')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Error in visualizing preprocessing: {e}\")\n",
    "\n",
    "def preprocess_dataset(data_paths, labels, augment=True, num_augmentations=2):\n",
    "    \"\"\"\n",
    "    Preprocess all images in the dataset\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for i, (img_path, label) in enumerate(zip(data_paths, labels)):\n",
    "        try:\n",
    "            # Apply preprocessing\n",
    "            img_preprocessed, _ = preprocess_image(img_path)\n",
    "            \n",
    "            # Skip if image is all zeros (failed to load)\n",
    "            if np.all(img_preprocessed == 0):\n",
    "                continue\n",
    "                \n",
    "            X.append(img_preprocessed)\n",
    "            y.append(label)\n",
    "            \n",
    "            # Apply augmentations if enabled\n",
    "            if augment:\n",
    "                for _ in range(num_augmentations):\n",
    "                    img_aug = apply_augmentation(img_preprocessed)\n",
    "                    X.append(img_aug)\n",
    "                    y.append(label)\n",
    "                    \n",
    "            # Print progress\n",
    "            if (i+1) % 50 == 0:\n",
    "                print(f\"Processed {i+1}/{len(data_paths)} images\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    if X:  # Only if we have data\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "    else:\n",
    "        print(\"Warning: No images were successfully processed!\")\n",
    "        X = np.array([])\n",
    "        y = np.array([])\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "#############################################################\n",
    "# CELL 3: SEGMENTATION (FROM SCRATCH)\n",
    "#############################################################\n",
    "\n",
    "def otsu_thresholding(image):\n",
    "    \"\"\"\n",
    "    Implement Otsu's thresholding from scratch with fixes for numeric issues\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert to grayscale if needed\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            gray = image.copy()\n",
    "        \n",
    "        # Convert to integers to avoid floating point errors\n",
    "        if gray.dtype == np.float32 or gray.dtype == np.float64:\n",
    "            gray = (gray * 255).astype(np.uint8)\n",
    "            \n",
    "        # Use OpenCV's Otsu implementation as a fallback if the image is suitable\n",
    "        if np.min(gray) < np.max(gray):  # Ensure image has variation\n",
    "            _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            return binary\n",
    "            \n",
    "        # If OpenCV's implementation fails or the image has no variation, return a blank mask\n",
    "        binary = np.zeros_like(gray)\n",
    "        return binary\n",
    "    except Exception as e:\n",
    "        print(f\"Error in Otsu thresholding: {e}\")\n",
    "        # Return blank binary image\n",
    "        if len(image.shape) == 3:\n",
    "            return np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
    "        else:\n",
    "            return np.zeros_like(image, dtype=np.uint8)\n",
    "\n",
    "def edge_based_segmentation(image):\n",
    "    \"\"\"\n",
    "    Implement edge-based segmentation using Canny edge detector\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert to grayscale if needed\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            gray = image.copy()\n",
    "        \n",
    "        # Convert to uint8 if needed\n",
    "        if gray.dtype == np.float32 or gray.dtype == np.float64:\n",
    "            gray = (gray * 255).astype(np.uint8)\n",
    "        \n",
    "        # Use Canny edge detector (more robust than simple Sobel filters)\n",
    "        edges = cv2.Canny(gray, 50, 150)\n",
    "        \n",
    "        # Dilate edges to make them more visible\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "        \n",
    "        return edges\n",
    "    except Exception as e:\n",
    "        print(f\"Error in edge-based segmentation: {e}\")\n",
    "        # Return blank binary image\n",
    "        if len(image.shape) == 3:\n",
    "            return np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
    "        else:\n",
    "            return np.zeros_like(image, dtype=np.uint8)\n",
    "\n",
    "def region_growing_segmentation(image, seed_points=None, threshold=10):\n",
    "    \"\"\"\n",
    "    Implement region growing segmentation with error handling\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert to grayscale if needed\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            gray = image.copy()\n",
    "        \n",
    "        # Convert to uint8 if needed\n",
    "        if gray.dtype == np.float32 or gray.dtype == np.float64:\n",
    "            gray = (gray * 255).astype(np.uint8)\n",
    "        \n",
    "        # Initialize output segmentation mask\n",
    "        segmented = np.zeros_like(gray, dtype=np.uint8)\n",
    "        \n",
    "        # If seed points are not provided, use 5 random points\n",
    "        if seed_points is None:\n",
    "            h, w = gray.shape\n",
    "            seed_points = []\n",
    "            for _ in range(5):\n",
    "                y = random.randint(0, h-1)\n",
    "                x = random.randint(0, w-1)\n",
    "                seed_points.append((y, x))\n",
    "        \n",
    "        # For each seed point\n",
    "        for seed_y, seed_x in seed_points:\n",
    "            # Limit seed points to image dimensions\n",
    "            if seed_y < 0 or seed_y >= gray.shape[0] or seed_x < 0 or seed_x >= gray.shape[1]:\n",
    "                continue\n",
    "            \n",
    "            # Initialize region with seed point\n",
    "            region = [(seed_y, seed_x)]\n",
    "            processed = np.zeros_like(gray, dtype=bool)\n",
    "            processed[seed_y, seed_x] = True\n",
    "            \n",
    "            # Get seed point intensity\n",
    "            seed_intensity = int(gray[seed_y, seed_x])\n",
    "            \n",
    "            # While there are pixels to process (limit region size to avoid infinite loops)\n",
    "            max_region_size = 10000  # Limit region size\n",
    "            region_count = 0\n",
    "            \n",
    "            while region and region_count < max_region_size:\n",
    "                # Get next pixel\n",
    "                y, x = region.pop(0)\n",
    "                segmented[y, x] = 255\n",
    "                region_count += 1\n",
    "                \n",
    "                # Check 4-connected neighbors\n",
    "                for dy, dx in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
    "                    ny, nx = y + dy, x + dx\n",
    "                    \n",
    "                    # Check if neighbor is within bounds\n",
    "                    if 0 <= ny < gray.shape[0] and 0 <= nx < gray.shape[1]:\n",
    "                        # Check if neighbor has not been processed\n",
    "                        if not processed[ny, nx]:\n",
    "                            # Check if neighbor intensity is similar to seed\n",
    "                            if abs(int(gray[ny, nx]) - seed_intensity) <= threshold:\n",
    "                                # Add neighbor to region\n",
    "                                region.append((ny, nx))\n",
    "                                processed[ny, nx] = True\n",
    "        \n",
    "        return segmented\n",
    "    except Exception as e:\n",
    "        print(f\"Error in region growing segmentation: {e}\")\n",
    "        # Return blank binary image\n",
    "        if len(image.shape) == 3:\n",
    "            return np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
    "        else:\n",
    "            return np.zeros_like(image, dtype=np.uint8)\n",
    "\n",
    "def k_means_segmentation(image, k=3, max_iterations=50):\n",
    "    \"\"\"\n",
    "    Implement simplified k-means clustering for segmentation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use OpenCV's K-means for better efficiency\n",
    "        if len(image.shape) == 3:\n",
    "            # Reshape image for k-means\n",
    "            pixel_values = image.reshape((-1, 3))\n",
    "            # Convert to float32\n",
    "            pixel_values = np.float32(pixel_values)\n",
    "            \n",
    "            # K-means parameters\n",
    "            criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, max_iterations, 1.0)\n",
    "            \n",
    "            # Apply k-means\n",
    "            _, labels, centers = cv2.kmeans(pixel_values, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "            \n",
    "            # Convert back to uint8 and reshape\n",
    "            centers = np.uint8(centers)\n",
    "            segmented_flat = centers[labels.flatten()]\n",
    "            segmented = segmented_flat.reshape(image.shape)\n",
    "            \n",
    "            # Get labels in original image shape\n",
    "            labels_2d = labels.reshape(image.shape[:2])\n",
    "            \n",
    "            return segmented, labels_2d\n",
    "        else:\n",
    "            # For grayscale images\n",
    "            pixel_values = image.reshape((-1, 1))\n",
    "            pixel_values = np.float32(pixel_values)\n",
    "            \n",
    "            criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, max_iterations, 1.0)\n",
    "            \n",
    "            _, labels, centers = cv2.kmeans(pixel_values, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "            \n",
    "            centers = np.uint8(centers)\n",
    "            segmented_flat = centers[labels.flatten()]\n",
    "            segmented = segmented_flat.reshape(image.shape)\n",
    "            \n",
    "            labels_2d = labels.reshape(image.shape)\n",
    "            \n",
    "            return segmented, labels_2d\n",
    "    except Exception as e:\n",
    "        print(f\"Error in k-means segmentation: {e}\")\n",
    "        # Return original image and zeros for labels as fallback\n",
    "        if len(image.shape) == 3:\n",
    "            if image.dtype == np.float32 or image.dtype == np.float64:\n",
    "                img = (image * 255).astype(np.uint8)\n",
    "            else:\n",
    "                img = image.copy()\n",
    "            return img, np.zeros((image.shape[0], image.shape[1]), dtype=np.int32)\n",
    "        else:\n",
    "            if image.dtype == np.float32 or image.dtype == np.float64:\n",
    "                img = (image * 255).astype(np.uint8)\n",
    "            else:\n",
    "                img = image.copy()\n",
    "            return img, np.zeros_like(image, dtype=np.int32)\n",
    "\n",
    "def apply_segmentation(image):\n",
    "    \"\"\"\n",
    "    Apply multiple segmentation techniques and combine results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert image to float32 if needed\n",
    "        if image.dtype != np.float32:\n",
    "            image_float = image.astype(np.float32)\n",
    "        else:\n",
    "            image_float = image.copy()\n",
    "        \n",
    "        # Scale to 0-1 if needed\n",
    "        if np.max(image_float) > 1.0:\n",
    "            image_float /= 255.0\n",
    "        \n",
    "        # Convert to uint8 for segmentation algorithms\n",
    "        image_uint8 = (image_float * 255).astype(np.uint8)\n",
    "        \n",
    "        # Apply different segmentation methods\n",
    "        otsu_result = otsu_thresholding(image_uint8)\n",
    "        edge_result = edge_based_segmentation(image_uint8)\n",
    "        region_result = region_growing_segmentation(image_uint8)\n",
    "        kmeans_result, _ = k_means_segmentation(image_float, k=3)\n",
    "        \n",
    "        # Combine segmentation results (weighted average)\n",
    "        # Create a float array to store combined results\n",
    "        combined = np.zeros_like(image_uint8[:,:,0], dtype=np.float32)\n",
    "        \n",
    "        # Add weighted contributions\n",
    "        combined += (otsu_result / 255.0) * 0.3  # Higher weight for Otsu\n",
    "        combined += (edge_result / 255.0) * 0.2  # Lower weight for edges\n",
    "        combined += (region_result / 255.0) * 0.2  # Lower weight for region growing\n",
    "        \n",
    "        # Convert kmeans result to grayscale and add to combined\n",
    "        kmeans_gray = cv2.cvtColor(kmeans_result, cv2.COLOR_RGB2GRAY) / 255.0\n",
    "        combined += kmeans_gray * 0.3  # Higher weight for k-means\n",
    "        \n",
    "        # Threshold combined result\n",
    "        combined = (combined > 0.4).astype(np.uint8) * 255\n",
    "        \n",
    "        # Find contours in combined segmentation\n",
    "        contours, _ = cv2.findContours(combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Create mask from contours\n",
    "        mask = np.zeros_like(combined)\n",
    "        cv2.drawContours(mask, contours, -1, 255, -1)\n",
    "        \n",
    "        # Apply mask to original image\n",
    "        segmented_img = image_uint8.copy()\n",
    "        for i in range(3):\n",
    "            segmented_img[:,:,i] = np.uint8(segmented_img[:,:,i] * (mask / 255.0))\n",
    "        \n",
    "        return segmented_img, mask\n",
    "    except Exception as e:\n",
    "        print(f\"Error in apply_segmentation: {e}\")\n",
    "        # Return original image and blank mask as fallback\n",
    "        if image.dtype == np.float32 or image.dtype == np.float64:\n",
    "            img = (image * 255).astype(np.uint8)\n",
    "        else:\n",
    "            img = image.copy()\n",
    "        mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
    "        return img, mask\n",
    "\n",
    "def visualize_segmentation(image_path):\n",
    "    \"\"\"\n",
    "    Visualize different segmentation methods on an example image\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load and preprocess image\n",
    "        preprocessed_img, original_img = preprocess_image(image_path)\n",
    "        img_uint8 = (preprocessed_img * 255).astype(np.uint8)\n",
    "        \n",
    "        # Apply segmentation methods\n",
    "        otsu_result = otsu_thresholding(img_uint8)\n",
    "        edge_result = edge_based_segmentation(img_uint8)\n",
    "        region_result = region_growing_segmentation(img_uint8)\n",
    "        kmeans_result, _ = k_means_segmentation(preprocessed_img, k=3)\n",
    "        segmented_img, mask = apply_segmentation(preprocessed_img)\n",
    "        \n",
    "        # Visualize results\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        plt.subplot(2, 3, 1)\n",
    "        plt.imshow(preprocessed_img)\n",
    "        plt.title('Preprocessed')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(2, 3, 2)\n",
    "        plt.imshow(otsu_result, cmap='gray')\n",
    "        plt.title('Otsu Thresholding')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(2, 3, 3)\n",
    "        plt.imshow(edge_result, cmap='gray')\n",
    "        plt.title('Edge-Based')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(2, 3, 4)\n",
    "        plt.imshow(region_result, cmap='gray')\n",
    "        plt.title('Region Growing')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(2, 3, 5)\n",
    "        plt.imshow(kmeans_result)\n",
    "        plt.title('K-Means (k=3)')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(2, 3, 6)\n",
    "        plt.imshow(segmented_img)\n",
    "        plt.title('Final Segmentation')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Error in visualize_segmentation: {e}\")\n",
    "\n",
    "#############################################################\n",
    "# CELL 4: FEATURE EXTRACTION\n",
    "#############################################################\n",
    "\n",
    "def extract_color_histogram(image, bins=32):\n",
    "    \"\"\"\n",
    "    Extract color histogram features\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Make sure image is in the correct format\n",
    "        if image.dtype != np.float32 and image.dtype != np.float64:\n",
    "            image = image.astype(np.float32) / 255.0\n",
    "            \n",
    "        # Normalize range to [0, 1] if needed\n",
    "        if np.max(image) > 1.0:\n",
    "            image = image / 255.0\n",
    "            \n",
    "        # Extract histograms for each channel\n",
    "        hist_r = np.histogram(image[:,:,0], bins=bins, range=(0, 1))[0]\n",
    "        hist_g = np.histogram(image[:,:,1], bins=bins, range=(0, 1))[0]\n",
    "        hist_b = np.histogram(image[:,:,2], bins=bins, range=(0, 1))[0]\n",
    "        \n",
    "        # Normalize histograms\n",
    "        hist_r = hist_r / (np.sum(hist_r) + 1e-10)  # Add small epsilon to avoid division by zero\n",
    "        hist_g = hist_g / (np.sum(hist_g) + 1e-10)\n",
    "        hist_b = hist_b / (np.sum(hist_b) + 1e-10)\n",
    "        \n",
    "        # Concatenate the histograms\n",
    "        hist_features = np.concatenate([hist_r, hist_g, hist_b])\n",
    "        \n",
    "        return hist_features\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_color_histogram: {e}\")\n",
    "        # Return zero vector as fallback\n",
    "        return np.zeros(bins * 3)\n",
    "\n",
    "def extract_texture_features(image):\n",
    "    \"\"\"\n",
    "    Extract texture features using simple statistical measures\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert to grayscale\n",
    "        if len(image.shape) == 3:\n",
    "            if image.dtype == np.float32 or image.dtype == np.float64:\n",
    "                # Scale to 0-255 for conversion\n",
    "                gray = cv2.cvtColor((image * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "            else:\n",
    "                gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            gray = image.copy()\n",
    "            \n",
    "        # Calculate simple texture statistics\n",
    "        mean = np.mean(gray) / 255.0\n",
    "        std = np.std(gray) / 255.0\n",
    "        \n",
    "        # Skip GLCM calculation if we had errors before\n",
    "        # Return basic texture features plus zeros for GLCM features\n",
    "        basic_features = np.array([mean, std])\n",
    "        glcm_features = np.zeros(5)  # Placeholder for GLCM features\n",
    "        \n",
    "        texture_features = np.concatenate([basic_features, glcm_features])\n",
    "        \n",
    "        # Return simplified texture features (without GLCM)\n",
    "        return texture_features\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_texture_features: {e}\")\n",
    "        # Return zero vector as fallback\n",
    "        return np.zeros(7)\n",
    "\n",
    "def extract_shape_features(segmentation_mask):\n",
    "    \"\"\"\n",
    "    Extract shape features from segmentation mask\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure mask is binary\n",
    "        if segmentation_mask.dtype != np.uint8:\n",
    "            mask = (segmentation_mask > 0).astype(np.uint8) * 255\n",
    "        else:\n",
    "            mask = segmentation_mask.copy()\n",
    "            \n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        if not contours:\n",
    "            # No contours found, return zeros\n",
    "            return np.zeros(5)\n",
    "        \n",
    "        # Get the largest contour\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        # Calculate area\n",
    "        area = cv2.contourArea(largest_contour)\n",
    "        \n",
    "        # Calculate perimeter\n",
    "        perimeter = cv2.arcLength(largest_contour, True)\n",
    "        \n",
    "        # Calculate circularity: 4*pi*area / perimeter^2\n",
    "        circularity = (4 * np.pi * area) / (perimeter * perimeter + 1e-10)  # Avoid division by zero\n",
    "        \n",
    "        # Calculate bounding rectangle\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        \n",
    "        # Calculate aspect ratio\n",
    "        aspect_ratio = float(w) / (h + 1e-10)  # Avoid division by zero\n",
    "        \n",
    "        # Calculate extent: ratio of contour area to bounding rectangle area\n",
    "        extent = float(area) / ((w * h) + 1e-10)  # Avoid division by zero\n",
    "        \n",
    "        # Normalize features\n",
    "        area_norm = min(area / 1000, 1.0)  # Cap at 1.0\n",
    "        perimeter_norm = min(perimeter / 100, 1.0)  # Cap at 1.0\n",
    "        \n",
    "        # Combine shape features\n",
    "        shape_features = np.array([area_norm, perimeter_norm, circularity, aspect_ratio, extent])\n",
    "        \n",
    "        # Handle infinities or NaNs\n",
    "        shape_features = np.nan_to_num(shape_features)\n",
    "        \n",
    "        return shape_features\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_shape_features: {e}\")\n",
    "        # Return zero vector as fallback\n",
    "        return np.zeros(5)\n",
    "\n",
    "def extract_enhanced_features(image):\n",
    "    \"\"\"\n",
    "    Extract enhanced features from an image with simplified Gabor filters\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Apply segmentation\n",
    "        segmented_img, mask = apply_segmentation(image)\n",
    "        \n",
    "        # Basic features\n",
    "        color_features = extract_color_histogram(image, bins=16)  # Reduced bins for efficiency\n",
    "        texture_features = extract_texture_features(image)\n",
    "        shape_features = extract_shape_features(mask)\n",
    "        \n",
    "        # Additional color features in HSV color space\n",
    "        if image.dtype == np.float32 or image.dtype == np.float64:\n",
    "            # Convert to uint8 for cv2.cvtColor\n",
    "            img_uint8 = (image * 255).astype(np.uint8)\n",
    "            hsv_img = cv2.cvtColor(img_uint8, cv2.COLOR_RGB2HSV) / 255.0\n",
    "        else:\n",
    "            hsv_img = cv2.cvtColor(image, cv2.COLOR_RGB2HSV) / 255.0\n",
    "            \n",
    "        hsv_hist = np.concatenate([\n",
    "            np.histogram(hsv_img[:,:,0], bins=10, range=(0, 1))[0],\n",
    "            np.histogram(hsv_img[:,:,1], bins=10, range=(0, 1))[0],\n",
    "            np.histogram(hsv_img[:,:,2], bins=10, range=(0, 1))[0]\n",
    "        ])\n",
    "        \n",
    "        # Normalize histograms\n",
    "        hsv_hist = hsv_hist / (np.sum(hsv_hist) + 1e-10)\n",
    "        \n",
    "        # Simplified Gabor features\n",
    "        gabor_features = []\n",
    "        # Use fewer Gabor parameters for efficiency\n",
    "        gray = cv2.cvtColor((image * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY) if image.dtype == np.float32 else cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        for theta in [0, np.pi/2]:  # Just 2 orientations\n",
    "            for sigma in [3.0]:  # Just 1 scale\n",
    "                # Create Gabor kernel\n",
    "                kernel = cv2.getGaborKernel((15, 15), sigma, theta, 1.0/0.2, 0.5, 0, ktype=cv2.CV_32F)\n",
    "                # Apply filter\n",
    "                filtered = cv2.filter2D(gray, cv2.CV_8UC3, kernel)\n",
    "                # Get mean and variance of response\n",
    "                gabor_features.extend([np.mean(filtered) / 255.0, np.std(filtered) / 255.0])\n",
    "        \n",
    "        # Edge histogram\n",
    "        edge_hist = np.histogram(edge_based_segmentation(image), bins=10)[0]\n",
    "        edge_hist = edge_hist / (np.sum(edge_hist) + 1e-10)\n",
    "        \n",
    "        # Combine all features\n",
    "        all_features = np.concatenate([\n",
    "            color_features,  # RGB histogram\n",
    "            hsv_hist,        # HSV color space\n",
    "            texture_features,\n",
    "            gabor_features,\n",
    "            edge_hist,\n",
    "            shape_features\n",
    "        ])\n",
    "        \n",
    "        # Handle any NaN or Inf values\n",
    "        all_features = np.nan_to_num(all_features)\n",
    "        \n",
    "        return all_features, segmented_img, mask\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_enhanced_features: {e}\")\n",
    "        # Return fallback features\n",
    "        fallback_features = np.zeros(100)  # Approximate size\n",
    "        if image.dtype == np.float32 or image.dtype == np.float64:\n",
    "            img = (image * 255).astype(np.uint8)\n",
    "        else:\n",
    "            img = image.copy()\n",
    "        mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
    "        return fallback_features, img, mask\n",
    "\n",
    "def extract_dataset_features(X):\n",
    "    \"\"\"\n",
    "    Extract features from all images in the dataset\n",
    "    \"\"\"\n",
    "    features_list = []\n",
    "    segmented_images = []\n",
    "    \n",
    "    for i, img in enumerate(X):\n",
    "        try:\n",
    "            # Extract features\n",
    "            features, segmented_img, _ = extract_enhanced_features(img)\n",
    "            features_list.append(features)\n",
    "            segmented_images.append(segmented_img)\n",
    "            \n",
    "            # Print progress\n",
    "            if (i+1) % 20 == 0:\n",
    "                print(f\"Extracted features from {i+1}/{len(X)} images\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting features for image {i}: {e}\")\n",
    "            # Add zero features as fallback\n",
    "            features_list.append(np.zeros(100))  # Approximate size\n",
    "            segmented_images.append(img)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    features_array = np.array(features_list)\n",
    "    segmented_images = np.array(segmented_images)\n",
    "    \n",
    "    return features_array, segmented_images\n",
    "\n",
    "def visualize_features(image_path):\n",
    "    \"\"\"\n",
    "    Visualize the extracted features\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load and preprocess image\n",
    "        preprocessed_img, original_img = preprocess_image(image_path)\n",
    "        \n",
    "        # Extract features\n",
    "        features, segmented_img, mask = extract_enhanced_features(preprocessed_img)\n",
    "        \n",
    "        # Get feature type counts\n",
    "        color_features_count = 48  # 16 bins * 3 channels \n",
    "        hsv_features_count = 30    # 10 bins * 3 channels\n",
    "        texture_features_count = 7 # 7 texture measurements\n",
    "        gabor_features_count = 4   # 2 orientations * 1 scale * 2 stats\n",
    "        edge_hist_count = 10       # 10 bins\n",
    "        shape_features_count = 5   # 5 shape measurements\n",
    "        \n",
    "        # Split features by type\n",
    "        color_features = features[:color_features_count]\n",
    "        hsv_features = features[color_features_count:color_features_count+hsv_features_count]\n",
    "        texture_features = features[color_features_count+hsv_features_count:\n",
    "                                   color_features_count+hsv_features_count+texture_features_count]\n",
    "        gabor_features = features[color_features_count+hsv_features_count+texture_features_count:\n",
    "                                 color_features_count+hsv_features_count+texture_features_count+gabor_features_count]\n",
    "        edge_hist = features[color_features_count+hsv_features_count+texture_features_count+gabor_features_count:\n",
    "                            color_features_count+hsv_features_count+texture_features_count+gabor_features_count+edge_hist_count]\n",
    "        shape_features = features[-shape_features_count:]\n",
    "        \n",
    "        # Visualize\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        plt.subplot(2, 3, 1)\n",
    "        plt.imshow(preprocessed_img)\n",
    "        plt.title('Preprocessed Image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(2, 3, 2)\n",
    "        plt.imshow(segmented_img)\n",
    "        plt.title('Segmented Image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(2, 3, 3)\n",
    "        plt.bar(range(len(color_features)), color_features)\n",
    "        plt.title('RGB Color Histogram')\n",
    "        plt.xlabel('Bin')\n",
    "        plt.ylabel('Normalized Frequency')\n",
    "        \n",
    "        plt.subplot(2, 3, 4)\n",
    "        plt.bar(range(len(hsv_features)), hsv_features)\n",
    "        plt.title('HSV Color Features')\n",
    "        plt.xlabel('Bin')\n",
    "        plt.ylabel('Normalized Frequency')\n",
    "        \n",
    "        plt.subplot(2, 3, 5)\n",
    "        feature_names = ['Mean', 'StdDev', 'Contrast', 'Dissim.', 'Homogen.', 'Correl.', 'ASM']\n",
    "        plt.bar(range(len(texture_features)), texture_features)\n",
    "        plt.xticks(range(len(texture_features)), feature_names, rotation=45)\n",
    "        plt.title('Texture Features')\n",
    "        \n",
    "        plt.subplot(2, 3, 6)\n",
    "        shape_feat_names = ['Area', 'Perim.', 'Circ.', 'Asp.Ratio', 'Extent']\n",
    "        plt.bar(range(len(shape_features)), shape_features)\n",
    "        plt.xticks(range(len(shape_features)), shape_feat_names, rotation=45)\n",
    "        plt.title('Shape Features')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Error in visualize_features: {e}\")\n",
    "\n",
    "#############################################################\n",
    "# CELL 5: CLASSIFICATION (FROM SCRATCH - SIMPLIFIED)\n",
    "#############################################################\n",
    "\n",
    "class SimpleNeuralNetwork:\n",
    "    \"\"\"\n",
    "    A simplified neural network implementation from scratch\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, dropout_rate=0.2):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.output_size = output_size\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        # Initialize network architecture\n",
    "        layer_sizes = [input_size] + hidden_sizes + [output_size]\n",
    "        \n",
    "        # Initialize weights and biases with proper scaling\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            # Xavier/Glorot initialization\n",
    "            scale = np.sqrt(2.0 / layer_sizes[i-1])\n",
    "            self.weights.append(np.random.randn(layer_sizes[i-1], layer_sizes[i]) * scale)\n",
    "            self.biases.append(np.zeros(layer_sizes[i]))\n",
    "    \n",
    "    def relu(self, x):\n",
    "        \"\"\"ReLU activation function\"\"\"\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        \"\"\"Softmax activation with numerical stability\"\"\"\n",
    "        x_shifted = x - np.max(x, axis=1, keepdims=True)\n",
    "        exp_x = np.exp(x_shifted)\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "    \n",
    "    def forward(self, X, training=False):\n",
    "        \"\"\"Forward pass through the network\"\"\"\n",
    "        # Store activations for backpropagation\n",
    "        self.layer_inputs = []\n",
    "        self.activations = [X]\n",
    "        \n",
    "        # Hidden layers with ReLU\n",
    "        for i in range(len(self.hidden_sizes)):\n",
    "            z = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]\n",
    "            self.layer_inputs.append(z)\n",
    "            \n",
    "            # ReLU activation\n",
    "            a = self.relu(z)\n",
    "            \n",
    "            # Apply dropout during training\n",
    "            if training and self.dropout_rate > 0:\n",
    "                mask = np.random.binomial(1, 1-self.dropout_rate, size=a.shape) / (1-self.dropout_rate)\n",
    "                a = a * mask\n",
    "                \n",
    "            self.activations.append(a)\n",
    "        \n",
    "        # Output layer with softmax\n",
    "        z_out = np.dot(self.activations[-1], self.weights[-1]) + self.biases[-1]\n",
    "        self.layer_inputs.append(z_out)\n",
    "        output = self.softmax(z_out)\n",
    "        self.activations.append(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        \"\"\"Compute cross-entropy loss\"\"\"\n",
    "        m = y_true.shape[0]\n",
    "        # Convert to one-hot if needed\n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true_one_hot = np.zeros((m, self.output_size))\n",
    "            y_true_one_hot[np.arange(m), y_true] = 1\n",
    "            y_true = y_true_one_hot\n",
    "            \n",
    "        # Cross-entropy loss\n",
    "        loss = -np.sum(y_true * np.log(y_pred + 1e-8)) / m\n",
    "        return loss\n",
    "        \n",
    "    def backward(self, X, y, learning_rate=0.01, l2_reg=0.001):\n",
    "        \"\"\"Backward pass and parameter update\"\"\"\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        # Convert y to one-hot\n",
    "        y_one_hot = np.zeros((m, self.output_size))\n",
    "        y_one_hot[np.arange(m), y] = 1\n",
    "        \n",
    "        # Output layer gradient (softmax + cross-entropy)\n",
    "        delta = self.activations[-1] - y_one_hot\n",
    "        \n",
    "        # Update layers from last to first\n",
    "        for i in range(len(self.weights)-1, -1, -1):\n",
    "            # Calculate gradients\n",
    "            dW = np.dot(self.activations[i].T, delta) / m + l2_reg * self.weights[i]\n",
    "            db = np.sum(delta, axis=0) / m\n",
    "            \n",
    "            # Update parameters\n",
    "            self.weights[i] -= learning_rate * dW\n",
    "            self.biases[i] -= learning_rate * db\n",
    "            \n",
    "            # Propagate gradients to previous layer (if not the input layer)\n",
    "            if i > 0:\n",
    "                # Derivative of ReLU: 1 if input > 0, else 0\n",
    "                relu_derivative = (self.layer_inputs[i-1] > 0).astype(float)\n",
    "                delta = np.dot(delta, self.weights[i].T) * relu_derivative\n",
    "    \n",
    "    def train(self, X, y, X_val=None, y_val=None, epochs=100, learning_rate=0.001, \n",
    "              batch_size=32, l2_reg=0.001, verbose=True, early_stopping=True):\n",
    "        \"\"\"Train the neural network\"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        losses = []\n",
    "        val_accuracies = []\n",
    "        \n",
    "        # Early stopping setup\n",
    "        best_val_acc = 0\n",
    "        patience = 20\n",
    "        wait = 0\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Shuffle data\n",
    "            indices = np.random.permutation(n_samples)\n",
    "            X_shuffled = X[indices]\n",
    "            y_shuffled = y[indices]\n",
    "            \n",
    "            # Mini-batch training\n",
    "            for i in range(0, n_samples, batch_size):\n",
    "                end = min(i + batch_size, n_samples)\n",
    "                batch_X = X_shuffled[i:end]\n",
    "                batch_y = y_shuffled[i:end]\n",
    "                \n",
    "                # Forward and backward pass\n",
    "                self.forward(batch_X, training=True)\n",
    "                self.backward(batch_X, batch_y, learning_rate, l2_reg)\n",
    "            \n",
    "            # Compute loss\n",
    "            y_pred = self.forward(X, training=False)\n",
    "            loss = self.compute_loss(y, y_pred)\n",
    "            losses.append(loss)\n",
    "            \n",
    "            # Compute validation accuracy\n",
    "            if X_val is not None and y_val is not None:\n",
    "                val_pred = self.predict(X_val)\n",
    "                val_accuracy = np.mean(val_pred == y_val)\n",
    "                val_accuracies.append(val_accuracy)\n",
    "                \n",
    "                # Early stopping\n",
    "                if early_stopping:\n",
    "                    if val_accuracy > best_val_acc:\n",
    "                        best_val_acc = val_accuracy\n",
    "                        wait = 0\n",
    "                    else:\n",
    "                        wait += 1\n",
    "                        if wait >= patience:\n",
    "                            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                            break\n",
    "                \n",
    "                if verbose and (epoch + 1) % 10 == 0:\n",
    "                    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "            else:\n",
    "                if verbose and (epoch + 1) % 10 == 0:\n",
    "                    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}\")\n",
    "        \n",
    "        return losses, val_accuracies\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels\"\"\"\n",
    "        probabilities = self.forward(X, training=False)\n",
    "        return np.argmax(probabilities, axis=1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities\"\"\"\n",
    "        return self.forward(X, training=False)\n",
    "\n",
    "def train_classifier(X_train, y_train, X_val, y_val, use_cnn=False):\n",
    "    \"\"\"\n",
    "    Train a simplified neural network classifier on the extracted features\n",
    "    \"\"\"\n",
    "    # Feature normalization with standard scaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    # Handle numerical issues\n",
    "    X_train_scaled = np.nan_to_num(X_train_scaled)\n",
    "    X_val_scaled = np.nan_to_num(X_val_scaled)\n",
    "    \n",
    "    # Create the neural network\n",
    "    print(\"Training neural network classifier on extracted features...\")\n",
    "    classifier = SimpleNeuralNetwork(\n",
    "        input_size=X_train_scaled.shape[1],\n",
    "        hidden_sizes=[256, 128],  # Simplified architecture\n",
    "        output_size=NUM_CLASSES,\n",
    "        dropout_rate=0.3\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    losses, val_accuracies = classifier.train(\n",
    "        X_train_scaled, y_train,\n",
    "        X_val_scaled, y_val,\n",
    "        epochs=150,  # Reduced for faster training\n",
    "        learning_rate=0.001,\n",
    "        batch_size=32,\n",
    "        l2_reg=0.001,\n",
    "        verbose=True,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    \n",
    "    # Final evaluation\n",
    "    val_predictions = classifier.predict(X_val_scaled)\n",
    "    val_accuracy = np.mean(val_predictions == y_val)\n",
    "    print(f\"Final validation accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    # Visualize training progress\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(losses)\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(val_accuracies)\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Attach scaler to classifier for predictions\n",
    "    classifier.scaler = scaler\n",
    "    \n",
    "    return classifier, val_accuracy\n",
    "\n",
    "#############################################################\n",
    "# CELL 6: EVALUATION AND PERFORMANCE METRICS\n",
    "#############################################################\n",
    "\n",
    "def evaluate_classifier(classifier, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the classifier and calculate performance metrics\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Scale the test data if we have a scaler\n",
    "        if hasattr(classifier, 'scaler'):\n",
    "            X_test_scaled = classifier.scaler.transform(X_test)\n",
    "        else:\n",
    "            X_test_scaled = X_test\n",
    "            \n",
    "        # Replace NaN or infinite values\n",
    "        X_test_scaled = np.nan_to_num(X_test_scaled)\n",
    "            \n",
    "        # Make predictions\n",
    "        y_pred = classifier.predict(X_test_scaled)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Calculate precision, recall, and F1-score\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        # Calculate confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(\"Classification Metrics:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1-score: {f1:.4f}\")\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.colorbar()\n",
    "        \n",
    "        # Add labels\n",
    "        tick_marks = np.arange(len(CLASS_NAMES))\n",
    "        plt.xticks(tick_marks, CLASS_NAMES, rotation=45)\n",
    "        plt.yticks(tick_marks, CLASS_NAMES)\n",
    "        \n",
    "        # Add values to confusion matrix cells\n",
    "        thresh = cm.max() / 2.\n",
    "        for i in range(cm.shape[0]):\n",
    "            for j in range(cm.shape[1]):\n",
    "                plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                        horizontalalignment=\"center\",\n",
    "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.show()\n",
    "        \n",
    "        return accuracy, precision, recall, f1, cm\n",
    "    except Exception as e:\n",
    "        print(f\"Error in evaluate_classifier: {e}\")\n",
    "        return 0, 0, 0, 0, None\n",
    "\n",
    "def visualize_predictions(classifier, X_test, y_test, feature_mode=True, num_samples=5):\n",
    "    \"\"\"\n",
    "    Visualize model predictions on test samples\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Scale the test data if we have a scaler\n",
    "        if hasattr(classifier, 'scaler') and feature_mode:\n",
    "            X_test_scaled = classifier.scaler.transform(X_test)\n",
    "            X_test_scaled = np.nan_to_num(X_test_scaled)\n",
    "        else:\n",
    "            X_test_scaled = X_test\n",
    "            \n",
    "        # Get random indices\n",
    "        indices = np.random.choice(len(X_test), min(num_samples, len(X_test)), replace=False)\n",
    "        \n",
    "        # Make predictions\n",
    "        if feature_mode:\n",
    "            predictions = classifier.predict(X_test_scaled[indices])\n",
    "            probabilities = classifier.predict_proba(X_test_scaled[indices])\n",
    "        else:\n",
    "            # Extract features first if X_test contains images\n",
    "            features_list = []\n",
    "            segmented_list = []\n",
    "            for img in X_test[indices]:\n",
    "                features, segmented, _ = extract_enhanced_features(img)\n",
    "                features_list.append(features)\n",
    "                segmented_list.append(segmented)\n",
    "            \n",
    "            features_array = np.array(features_list)\n",
    "            segmented_array = np.array(segmented_list)\n",
    "            \n",
    "            # Scale features if we have a scaler\n",
    "            if hasattr(classifier, 'scaler'):\n",
    "                features_array = classifier.scaler.transform(features_array)\n",
    "                features_array = np.nan_to_num(features_array)\n",
    "                \n",
    "            predictions = classifier.predict(features_array)\n",
    "            probabilities = classifier.predict_proba(features_array)\n",
    "            \n",
    "            # Use segmented images for visualization\n",
    "            X_display = segmented_array\n",
    "        \n",
    "        # Plot images with predictions\n",
    "        plt.figure(figsize=(15, 3 * num_samples))\n",
    "        \n",
    "        for i, idx in enumerate(indices):\n",
    "            plt.subplot(num_samples, 2, 2*i+1)\n",
    "            if feature_mode:\n",
    "                # If we're in feature mode, can't display the features directly\n",
    "                # Display a bar chart of the feature values instead\n",
    "                plt.bar(range(min(20, len(X_test[idx]))), X_test[idx][:20])\n",
    "                plt.title(f\"Features (first 20)\")\n",
    "            else:\n",
    "                plt.imshow(X_display[i])\n",
    "                plt.title(f\"Image\")\n",
    "                plt.axis('off')\n",
    "            \n",
    "            plt.subplot(num_samples, 2, 2*i+2)\n",
    "            bars = plt.bar(range(NUM_CLASSES), probabilities[i])\n",
    "            plt.xticks(range(NUM_CLASSES), CLASS_NAMES)\n",
    "            plt.ylim(0, 1)\n",
    "            plt.title(f\"True: {CLASS_NAMES[y_test[idx]]}, Pred: {CLASS_NAMES[predictions[i]]}\")\n",
    "            \n",
    "            # Color the bars based on correctness\n",
    "            for j, bar in enumerate(bars):\n",
    "                if j == y_test[idx] and j == predictions[i]:\n",
    "                    bar.set_color('green')  # Correct prediction\n",
    "                elif j == y_test[idx]:\n",
    "                    bar.set_color('red')    # Missed true class\n",
    "                elif j == predictions[i]:\n",
    "                    bar.set_color('orange') # Wrong prediction\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Error in visualize_predictions: {e}\")\n",
    "\n",
    "#############################################################\n",
    "# CELL 7: GUI IMPLEMENTATION\n",
    "#############################################################\n",
    "\n",
    "class RecycledMaterialsClassifierGUI:\n",
    "    \"\"\"\n",
    "    GUI for the recycled materials classifier\n",
    "    \"\"\"\n",
    "    def __init__(self, root, classifier):\n",
    "        self.root = root\n",
    "        self.root.title(\"Recycled Materials Classifier\")\n",
    "        self.root.geometry(\"800x600\")\n",
    "        \n",
    "        self.classifier = classifier\n",
    "        \n",
    "        # Create frames\n",
    "        self.top_frame = tk.Frame(root)\n",
    "        self.top_frame.pack(pady=10)\n",
    "        \n",
    "        self.image_frame = tk.Frame(root)\n",
    "        self.image_frame.pack(pady=10, expand=True, fill=tk.BOTH)\n",
    "        \n",
    "        self.bottom_frame = tk.Frame(root)\n",
    "        self.bottom_frame.pack(pady=10)\n",
    "        \n",
    "        # Create widgets\n",
    "        self.create_widgets()\n",
    "        \n",
    "        # Initialize variables\n",
    "        self.image_path = None\n",
    "        self.image = None\n",
    "        self.processed_image = None\n",
    "        self.tk_image = None\n",
    "        \n",
    "    def create_widgets(self):\n",
    "        # Top frame: buttons\n",
    "        self.load_button = tk.Button(self.top_frame, text=\"Load Image\", command=self.load_image)\n",
    "        self.load_button.pack(side=tk.LEFT, padx=10)\n",
    "        \n",
    "        self.detect_button = tk.Button(self.top_frame, text=\"Detect Objects\", command=self.detect_objects)\n",
    "        self.detect_button.pack(side=tk.LEFT, padx=10)\n",
    "        \n",
    "        # Image frame: display image\n",
    "        self.canvas = tk.Canvas(self.image_frame, bg=\"white\")\n",
    "        self.canvas.pack(expand=True, fill=tk.BOTH)\n",
    "        \n",
    "        # Bottom frame: results\n",
    "        self.result_label = tk.Label(self.bottom_frame, text=\"Load an image and click 'Detect Objects'\")\n",
    "        self.result_label.pack()\n",
    "\n",
    "    def load_image(self):\n",
    "        \"\"\"Load an image from file\"\"\"\n",
    "        try:\n",
    "            self.image_path = filedialog.askopenfilename(\n",
    "                title=\"Select Image\",\n",
    "                filetypes=[(\"Image files\", \"*.png *.jpg *.jpeg\")]\n",
    "            )\n",
    "            \n",
    "            if not self.image_path:\n",
    "                return  # User canceled\n",
    "                \n",
    "            print(f\"Loading image from: {self.image_path}\")  # Debug print\n",
    "            \n",
    "            # Load image with PIL first (more robust)\n",
    "            pil_img = Image.open(self.image_path)\n",
    "            self.image = np.array(pil_img.convert('RGB'))\n",
    "            \n",
    "            # Display image\n",
    "            h, w = self.image.shape[:2]\n",
    "            canvas_w = self.canvas.winfo_width()\n",
    "            canvas_h = self.canvas.winfo_height()\n",
    "            \n",
    "            # Ensure canvas has a size\n",
    "            if canvas_w <= 1:\n",
    "                canvas_w = 700\n",
    "                canvas_h = 500\n",
    "            \n",
    "            # Calculate resize ratio\n",
    "            ratio = min(canvas_w / w, canvas_h / h)\n",
    "            new_size = (int(w * ratio), int(h * ratio))\n",
    "            \n",
    "            # Resize image for display\n",
    "            display_image = cv2.resize(self.image, new_size)\n",
    "            \n",
    "            pil_display = Image.fromarray(display_image)\n",
    "            self.tk_image = ImageTk.PhotoImage(pil_display)\n",
    "            \n",
    "            # Display on canvas\n",
    "            self.canvas.config(width=new_size[0], height=new_size[1])\n",
    "            self.canvas.create_image(0, 0, anchor=tk.NW, image=self.tk_image)\n",
    "            \n",
    "            self.result_label.config(text=\"Image loaded. Click 'Detect Objects'\")\n",
    "        except Exception as e:\n",
    "            print(f\"Detailed error loading image: {str(e)}\")  # More detailed error\n",
    "            self.result_label.config(text=f\"Error loading image: {str(e)}\")\n",
    "            \n",
    "    def detect_box_like_objects(self, image):\n",
    "        \"\"\"Specialized detection for box-like objects\"\"\"\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        # Apply bilateral filter to preserve edges while removing noise\n",
    "        filtered = cv2.bilateralFilter(gray, 9, 75, 75)\n",
    "        \n",
    "        # Edge detection with Canny\n",
    "        edges = cv2.Canny(filtered, 50, 150)\n",
    "        \n",
    "        # Dilate to connect nearby edges\n",
    "        kernel = np.ones((5,5), np.uint8)\n",
    "        dilated = cv2.dilate(edges, kernel, iterations=2)\n",
    "        \n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Create mask\n",
    "        mask = np.zeros_like(gray)\n",
    "        \n",
    "        # Draw contours with approximated polygons for rectangles\n",
    "        for contour in contours:\n",
    "            # Approximate polygon\n",
    "            epsilon = 0.04 * cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "            \n",
    "            # If it has 4-6 vertices, likely a rectangular box\n",
    "            if 4 <= len(approx) <= 6:\n",
    "                cv2.drawContours(mask, [approx], 0, 255, -1)\n",
    "            else:\n",
    "                # For non-rectangular contours, just fill the bounding rect\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                cv2.rectangle(mask, (x, y), (x+w, y+h), 255, -1)\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def detect_metal_objects(self, image):\n",
    "        \"\"\"Specialized detection for metal objects\"\"\"\n",
    "        # Convert to HSV for better color separation\n",
    "        hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        \n",
    "        # Extract value channel (brightness)\n",
    "        _, _, v = cv2.split(hsv)\n",
    "        \n",
    "        # Metal often appears bright and reflective\n",
    "        # Apply adaptive thresholding\n",
    "        thresh = cv2.adaptiveThreshold(v, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                      cv2.THRESH_BINARY, 11, 2)\n",
    "        \n",
    "        # Also look for gray/silver colors\n",
    "        lower_gray = np.array([0, 0, 100])\n",
    "        upper_gray = np.array([180, 30, 220])\n",
    "        gray_mask = cv2.inRange(hsv, lower_gray, upper_gray)\n",
    "        \n",
    "        # Combine masks\n",
    "        combined = cv2.bitwise_or(thresh, gray_mask)\n",
    "        \n",
    "        # Clean up with morphological operations\n",
    "        kernel = np.ones((5,5), np.uint8)\n",
    "        mask = cv2.morphologyEx(combined, cv2.MORPH_CLOSE, kernel)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def detect_plastic_objects(self, image):\n",
    "        \"\"\"Specialized detection for plastic objects\"\"\"\n",
    "        # Convert to HSV for better color segmentation\n",
    "        hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        \n",
    "        # Define multiple color ranges for common plastic colors\n",
    "        \n",
    "        # Transparent/white plastic\n",
    "        lower_white = np.array([0, 0, 180])\n",
    "        upper_white = np.array([180, 40, 255])\n",
    "        white_mask = cv2.inRange(hsv, lower_white, upper_white)\n",
    "        \n",
    "        # Colored plastics (high saturation)\n",
    "        lower_colored = np.array([0, 100, 100])\n",
    "        upper_colored = np.array([180, 255, 255])\n",
    "        colored_mask = cv2.inRange(hsv, lower_colored, upper_colored)\n",
    "        \n",
    "        # Black/dark plastic\n",
    "        lower_dark = np.array([0, 0, 0])\n",
    "        upper_dark = np.array([180, 255, 50])\n",
    "        dark_mask = cv2.inRange(hsv, lower_dark, upper_dark)\n",
    "        \n",
    "        # Combine all masks\n",
    "        combined = cv2.bitwise_or(white_mask, colored_mask)\n",
    "        combined = cv2.bitwise_or(combined, dark_mask)\n",
    "        \n",
    "        # Clean up with morphological operations\n",
    "        kernel = np.ones((7,7), np.uint8)\n",
    "        mask = cv2.morphologyEx(combined, cv2.MORPH_CLOSE, kernel)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def generic_object_detection(self, image):\n",
    "        \"\"\"Generic object detection as fallback\"\"\"\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        # Simple thresholding with Otsu's method\n",
    "        _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        \n",
    "        # Also try adaptive thresholding\n",
    "        adaptive_thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                               cv2.THRESH_BINARY, 11, 2)\n",
    "        \n",
    "        # Combine thresholds\n",
    "        combined = cv2.bitwise_or(thresh, adaptive_thresh)\n",
    "        \n",
    "        # Clean up\n",
    "        kernel = np.ones((5,5), np.uint8)\n",
    "        mask = cv2.morphologyEx(combined, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def detect_objects(self):\n",
    "        \"\"\"Advanced object detection for recycled materials with specialized segmentation\"\"\"\n",
    "        if self.image is None:\n",
    "            self.result_label.config(text=\"Please load an image first\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Preprocess image\n",
    "            resized_image = cv2.resize(self.image, IMAGE_SIZE)\n",
    "            normalized_image = resized_image.astype(np.float32) / 255.0\n",
    "            \n",
    "            # Extract features for classification\n",
    "            features, _, _ = extract_enhanced_features(normalized_image)\n",
    "            \n",
    "            # Make prediction\n",
    "            features_reshaped = features.reshape(1, -1)\n",
    "            if hasattr(self.classifier, 'scaler'):\n",
    "                features_scaled = self.classifier.scaler.transform(features_reshaped)\n",
    "                features_scaled = np.nan_to_num(features_scaled)\n",
    "            else:\n",
    "                features_scaled = features_reshaped\n",
    "                \n",
    "            # Get the prediction and confidence\n",
    "            prediction = self.classifier.predict(features_scaled)[0]\n",
    "            probabilities = self.classifier.predict_proba(features_scaled)[0]\n",
    "            confidence = probabilities[prediction] * 100\n",
    "            \n",
    "            # Convert to uint8 for processing\n",
    "            img_uint8 = (normalized_image * 255).astype(np.uint8)\n",
    "            display_image = self.image.copy()\n",
    "            \n",
    "            # ===== SPECIALIZED SEGMENTATION BASED ON MATERIAL TYPE =====\n",
    "            \n",
    "            # Class-specific segmentation\n",
    "            if CLASS_NAMES[prediction] == 'Boxes':\n",
    "                # For boxes: Use edge detection and rectangle fitting\n",
    "                mask = self.detect_box_like_objects(img_uint8)\n",
    "            elif CLASS_NAMES[prediction] == 'Metal':\n",
    "                # For metal: Use brightness and texture-based segmentation\n",
    "                mask = self.detect_metal_objects(img_uint8)\n",
    "            elif CLASS_NAMES[prediction] == 'Plastic':\n",
    "                # For plastic: Use color-based segmentation\n",
    "                mask = self.detect_plastic_objects(img_uint8)\n",
    "            else:\n",
    "                # Generic approach if class isn't recognized\n",
    "                mask = self.generic_object_detection(img_uint8)\n",
    "            \n",
    "            # Find contours in the mask\n",
    "            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            # Filter and process contours\n",
    "            if contours:\n",
    "                # Get the scaling factors\n",
    "                scale_x = display_image.shape[1] / img_uint8.shape[1]\n",
    "                scale_y = display_image.shape[0] / img_uint8.shape[0]\n",
    "                \n",
    "                # Sort contours by area (descending)\n",
    "                contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "                \n",
    "                # Take the largest 3 contours at most\n",
    "                for i, contour in enumerate(contours[:3]):\n",
    "                    if cv2.contourArea(contour) < 100:  # Skip very small contours\n",
    "                        continue\n",
    "                        \n",
    "                    # Get bounding box\n",
    "                    x, y, w, h = cv2.boundingRect(contour)\n",
    "                    \n",
    "                    # Scale to original image dimensions\n",
    "                    x_scaled = int(x * scale_x)\n",
    "                    y_scaled = int(y * scale_y)\n",
    "                    w_scaled = int(w * scale_x)\n",
    "                    h_scaled = int(h * scale_y)\n",
    "                    \n",
    "                    # Draw a professional-looking bounding box with color based on class\n",
    "                    if CLASS_NAMES[prediction] == 'Boxes':\n",
    "                        color = (0, 165, 255)  # Orange for boxes\n",
    "                    elif CLASS_NAMES[prediction] == 'Metal':\n",
    "                        color = (128, 128, 128)  # Gray for metal\n",
    "                    elif CLASS_NAMES[prediction] == 'Plastic':\n",
    "                        color = (0, 255, 255)  # Yellow for plastic\n",
    "                    else:\n",
    "                        color = (0, 255, 0)  # Green default\n",
    "                    \n",
    "                    # Draw main rectangle\n",
    "                    cv2.rectangle(display_image, \n",
    "                                 (x_scaled, y_scaled), \n",
    "                                 (x_scaled + w_scaled, y_scaled + h_scaled), \n",
    "                                 color, 3)\n",
    "                    \n",
    "                    # Draw corners\n",
    "                    corner_length = min(40, int(min(w_scaled, h_scaled) * 0.2))\n",
    "                    \n",
    "                    # Top-left\n",
    "                    cv2.line(display_image, (x_scaled, y_scaled), (x_scaled + corner_length, y_scaled), color, 5)\n",
    "                    cv2.line(display_image, (x_scaled, y_scaled), (x_scaled, y_scaled + corner_length), color, 5)\n",
    "                    \n",
    "                    # Top-right\n",
    "                    cv2.line(display_image, (x_scaled + w_scaled, y_scaled), (x_scaled + w_scaled - corner_length, y_scaled), color, 5)\n",
    "                    cv2.line(display_image, (x_scaled + w_scaled, y_scaled), (x_scaled + w_scaled, y_scaled + corner_length), color, 5)\n",
    "                    \n",
    "                    # Bottom-left\n",
    "                    cv2.line(display_image, (x_scaled, y_scaled + h_scaled), (x_scaled + corner_length, y_scaled + h_scaled), color, 5)\n",
    "                    cv2.line(display_image, (x_scaled, y_scaled + h_scaled), (x_scaled, y_scaled + h_scaled - corner_length), color, 5)\n",
    "                    \n",
    "                    # Bottom-right\n",
    "                    cv2.line(display_image, (x_scaled + w_scaled, y_scaled + h_scaled), (x_scaled + w_scaled - corner_length, y_scaled + h_scaled), color, 5)\n",
    "                    cv2.line(display_image, (x_scaled + w_scaled, y_scaled + h_scaled), (x_scaled + w_scaled, y_scaled + h_scaled - corner_length), color, 5)\n",
    "                    \n",
    "                    # Add label with background\n",
    "                    label = f\"{CLASS_NAMES[prediction]}: {confidence:.1f}%\"\n",
    "                    \n",
    "                    # Better text rendering\n",
    "                    font_scale = 0.8\n",
    "                    font_thickness = 2\n",
    "                    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    text_size, _ = cv2.getTextSize(label, font, font_scale, font_thickness)\n",
    "                    \n",
    "                    # Create background rectangle for text\n",
    "                    cv2.rectangle(display_image, \n",
    "                                 (x_scaled, y_scaled - text_size[1] - 10), \n",
    "                                 (x_scaled + text_size[0] + 10, y_scaled), \n",
    "                                 color, -1)\n",
    "                    \n",
    "                    # Add text\n",
    "                    cv2.putText(display_image, label, \n",
    "                               (x_scaled + 5, y_scaled - 7), \n",
    "                               font, font_scale, (255, 255, 255), font_thickness)\n",
    "            else:\n",
    "                # Fallback: draw box around the whole image\n",
    "                h, w = display_image.shape[:2]\n",
    "                margin = int(min(h, w) * 0.1)\n",
    "                color = (0, 255, 0)  # Default green\n",
    "                \n",
    "                cv2.rectangle(display_image, \n",
    "                             (margin, margin), \n",
    "                             (w - margin, h - margin), \n",
    "                             color, 3)\n",
    "                \n",
    "                # Add label\n",
    "                label = f\"{CLASS_NAMES[prediction]}: {confidence:.1f}%\"\n",
    "                font_scale = 1.0\n",
    "                font_thickness = 2\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                text_size, _ = cv2.getTextSize(label, font, font_scale, font_thickness)\n",
    "                \n",
    "                # Create background rectangle for text\n",
    "                cv2.rectangle(display_image, \n",
    "                             (margin, margin - text_size[1] - 10), \n",
    "                             (margin + text_size[0] + 10, margin), \n",
    "                             color, -1)\n",
    "                \n",
    "                # Add text\n",
    "                cv2.putText(display_image, label, \n",
    "                           (margin + 5, margin - 7), \n",
    "                           font, font_scale, (255, 255, 255), font_thickness)\n",
    "            \n",
    "            # Create result string\n",
    "            result_text = f\"Prediction: {CLASS_NAMES[prediction]} (Confidence: {confidence:.2f}%)\"\n",
    "            \n",
    "            # Resize for display\n",
    "            h, w = display_image.shape[:2]\n",
    "            canvas_w = self.canvas.winfo_width()\n",
    "            canvas_h = self.canvas.winfo_height()\n",
    "            \n",
    "            # Calculate resize ratio\n",
    "            ratio = min(canvas_w / w, canvas_h / h)\n",
    "            new_size = (int(w * ratio), int(h * ratio))\n",
    "            \n",
    "            display_image = cv2.resize(display_image, new_size)\n",
    "            \n",
    "            # Convert to PhotoImage\n",
    "            pil_image = Image.fromarray(display_image)\n",
    "            self.tk_image = ImageTk.PhotoImage(pil_image)\n",
    "            \n",
    "            # Display on canvas\n",
    "            self.canvas.create_image(0, 0, anchor=tk.NW, image=self.tk_image)\n",
    "            \n",
    "            # Update result label\n",
    "            self.result_label.config(text=result_text)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Detailed error in detection: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()  # Print stack trace for debugging\n",
    "            self.result_label.config(text=f\"Error during detection: {str(e)}\")\n",
    "\n",
    "#############################################################\n",
    "# CELL 8: MAIN EXECUTION\n",
    "#############################################################\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to execute the pipeline\n",
    "    \"\"\"\n",
    "    print(\"Starting Recycled Materials Classification Pipeline\")\n",
    "    \n",
    "    # 1. Load dataset\n",
    "    print(\"\\n=== Loading Dataset ===\")\n",
    "    (train_paths, train_labels), (test_paths, test_labels) = load_dataset()\n",
    "    \n",
    "    if not train_paths:\n",
    "        print(\"Error: No training data found. Please check your dataset path.\")\n",
    "        return\n",
    "    \n",
    "    # Visualize some samples\n",
    "    print(\"\\nVisualizing sample images...\")\n",
    "    visualize_dataset_samples(train_paths, train_labels, num_samples=2)\n",
    "    \n",
    "    # 2. Preprocess images\n",
    "    print(\"\\n=== Preprocessing Images ===\")\n",
    "    # Visualize preprocessing on sample image\n",
    "    if train_paths:\n",
    "        print(\"\\nVisualizing preprocessing steps...\")\n",
    "        visualize_preprocessing(train_paths[0])\n",
    "    \n",
    "    # Preprocess all images\n",
    "    print(\"\\nPreprocessing training images...\")\n",
    "    X_train_preprocessed = []\n",
    "    for i, path in enumerate(train_paths):\n",
    "        img, _ = preprocess_image(path)\n",
    "        if not np.all(img == 0):  # Skip failed images\n",
    "            X_train_preprocessed.append(img)\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Processed {i+1}/{len(train_paths)} images\")\n",
    "    X_train_preprocessed = np.array(X_train_preprocessed)\n",
    "    \n",
    "    print(\"\\nPreprocessing test images...\")\n",
    "    X_test_preprocessed = []\n",
    "    for i, path in enumerate(test_paths):\n",
    "        img, _ = preprocess_image(path)\n",
    "        if not np.all(img == 0):  # Skip failed images\n",
    "            X_test_preprocessed.append(img)\n",
    "        if (i+1) % 50 == 0:\n",
    "            print(f\"Processed {i+1}/{len(test_paths)} images\")\n",
    "    X_test_preprocessed = np.array(X_test_preprocessed)\n",
    "    \n",
    "    print(f\"Preprocessed dataset shapes: Train {X_train_preprocessed.shape}, Test {X_test_preprocessed.shape}\")\n",
    "    \n",
    "    # 3. Apply segmentation\n",
    "    print(\"\\n=== Applying Segmentation ===\")\n",
    "    # Visualize segmentation on sample image\n",
    "    if train_paths:\n",
    "        print(\"\\nVisualizing segmentation methods...\")\n",
    "        visualize_segmentation(train_paths[0])\n",
    "    \n",
    "    # 4. Extract features\n",
    "    print(\"\\n=== Extracting Enhanced Features ===\")\n",
    "    # Visualize features on sample image\n",
    "    if train_paths:\n",
    "        print(\"\\nVisualizing enhanced feature extraction...\")\n",
    "        visualize_features(train_paths[0])\n",
    "    \n",
    "    # Extract enhanced features from all images\n",
    "    print(\"\\nExtracting enhanced features from all images...\")\n",
    "    X_train_features = []\n",
    "    y_train = []  # We need to recreate labels to match processed images\n",
    "    for i, (img, label) in enumerate(zip(X_train_preprocessed, train_labels)):\n",
    "        try:\n",
    "            features, _, _ = extract_enhanced_features(img)\n",
    "            if not np.any(np.isnan(features)) and not np.any(np.isinf(features)):\n",
    "                X_train_features.append(features)\n",
    "                y_train.append(label)\n",
    "                \n",
    "            if (i+1) % 20 == 0:\n",
    "                print(f\"Extracted features from {i+1}/{len(X_train_preprocessed)} images\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting features from training image {i}: {e}\")\n",
    "\n",
    "    X_test_features = []\n",
    "    y_test = []  # We need to recreate labels to match processed images\n",
    "    for i, (img, label) in enumerate(zip(X_test_preprocessed, test_labels)):\n",
    "        try:\n",
    "            features, _, _ = extract_enhanced_features(img)\n",
    "            if not np.any(np.isnan(features)) and not np.any(np.isinf(features)):\n",
    "                X_test_features.append(features)\n",
    "                y_test.append(label)\n",
    "                \n",
    "            if (i+1) % 20 == 0:\n",
    "                print(f\"Extracted features from {i+1}/{len(X_test_preprocessed)} images\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting features from test image {i}: {e}\")\n",
    "\n",
    "    X_train_features = np.array(X_train_features)\n",
    "    X_test_features = np.array(X_test_features)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    print(f\"Extracted features shapes: Train {X_train_features.shape}, Test {X_test_features.shape}\")\n",
    "    \n",
    "    # Split training data into train and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_features, y_train, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 5. Train classifier\n",
    "    print(\"\\n=== Training Improved Classifier ===\")\n",
    "    classifier, val_accuracy = train_classifier(X_train, y_train, X_val, y_val, use_cnn=False)\n",
    "    \n",
    "    # 6. Evaluate classifier\n",
    "    print(\"\\n=== Evaluating Classifier ===\")\n",
    "    accuracy, precision, recall, f1, cm = evaluate_classifier(classifier, X_test_features, y_test)\n",
    "    \n",
    "    # 7. Save the model\n",
    "    print(\"\\n=== Saving Model ===\")\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    with open('models/recycled_materials_classifier.pkl', 'wb') as f:\n",
    "        pickle.dump(classifier, f)\n",
    "    \n",
    "    print(\"Model saved to 'models/recycled_materials_classifier.pkl'\")\n",
    "    \n",
    "    # 8. Launch GUI\n",
    "    print(\"\\n=== Launching GUI ===\")\n",
    "    print(\"Close the GUI window to exit the program\")\n",
    "    \n",
    "    root = tk.Tk()\n",
    "    app = RecycledMaterialsClassifierGUI(root, classifier)\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(42)\n",
    "    random.seed(42)\n",
    "    \n",
    "    try:\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
